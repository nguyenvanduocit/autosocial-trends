---
source: github
title: vllm-project/vllm-omni
url: https://github.com/vllm-project/vllm-omni
date: 2025-12-24
---

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm-omni)

Appearance settings

* Platform

  + AI CODE CREATION
    - [GitHub CopilotWrite better code with AI](https://github.com/features/copilot)
    - [GitHub SparkBuild and deploy intelligent apps](https://github.com/features/spark)
    - [GitHub ModelsManage and compare prompts](https://github.com/features/models)
    - [MCP RegistryNewIntegrate external tools](https://github.com/mcp)
  + DEVELOPER WORKFLOWS
    - [ActionsAutomate any workflow](https://github.com/features/actions)
    - [CodespacesInstant dev environments](https://github.com/features/codespaces)
    - [IssuesPlan and track work](https://github.com/features/issues)
    - [Code ReviewManage code changes](https://github.com/features/code-review)
  + APPLICATION SECURITY
    - [GitHub Advanced SecurityFind and fix vulnerabilities](https://github.com/security/advanced-security)
    - [Code securitySecure your code as you build](https://github.com/security/advanced-security/code-security)
    - [Secret protectionStop leaks before they start](https://github.com/security/advanced-security/secret-protection)
  + EXPLORE
    - [Why GitHub](https://github.com/why-github)
    - [Documentation](https://docs.github.com)
    - [Blog](https://github.blog)
    - [Changelog](https://github.blog/changelog)
    - [Marketplace](https://github.com/marketplace)

  [View all features](https://github.com/features)
* Solutions

  + BY COMPANY SIZE
    - [Enterprises](https://github.com/enterprise)
    - [Small and medium teams](https://github.com/team)
    - [Startups](https://github.com/enterprise/startups)
    - [Nonprofits](https://github.com/solutions/industry/nonprofits)
  + BY USE CASE
    - [App Modernization](https://github.com/solutions/use-case/app-modernization)
    - [DevSecOps](https://github.com/solutions/use-case/devsecops)
    - [DevOps](https://github.com/solutions/use-case/devops)
    - [CI/CD](https://github.com/solutions/use-case/ci-cd)
    - [View all use cases](https://github.com/solutions/use-case)
  + BY INDUSTRY
    - [Healthcare](https://github.com/solutions/industry/healthcare)
    - [Financial services](https://github.com/solutions/industry/financial-services)
    - [Manufacturing](https://github.com/solutions/industry/manufacturing)
    - [Government](https://github.com/solutions/industry/government)
    - [View all industries](https://github.com/solutions/industry)

  [View all solutions](https://github.com/solutions)
* Resources

  + EXPLORE BY TOPIC
    - [AI](https://github.com/resources/articles?topic=ai)
    - [Software Development](https://github.com/resources/articles?topic=software-development)
    - [DevOps](https://github.com/resources/articles?topic=devops)
    - [Security](https://github.com/resources/articles?topic=security)
    - [View all topics](https://github.com/resources/articles)
  + EXPLORE BY TYPE
    - [Customer stories](https://github.com/customer-stories)
    - [Events & webinars](https://github.com/resources/events)
    - [Ebooks & reports](https://github.com/resources/whitepapers)
    - [Business insights](https://github.com/solutions/executive-insights)
    - [GitHub Skills](https://skills.github.com)
  + SUPPORT & SERVICES
    - [Documentation](https://docs.github.com)
    - [Customer support](https://support.github.com)
    - [Community forum](https://github.com/orgs/community/discussions)
    - [Trust center](https://github.com/trust-center)
    - [Partners](https://github.com/partners)
* Open Source

  + COMMUNITY
    - [GitHub SponsorsFund open source developers](https://github.com/sponsors)
  + PROGRAMS
    - [Security Lab](https://securitylab.github.com)
    - [Maintainer Community](https://maintainers.github.com)
    - [Accelerator](https://github.com/accelerator)
    - [Archive Program](https://archiveprogram.github.com)
  + REPOSITORIES
    - [Topics](https://github.com/topics)
    - [Trending](https://github.com/trending)
    - [Collections](https://github.com/collections)
* Enterprise

  + ENTERPRISE SOLUTIONS
    - [Enterprise platformAI-powered developer platform](https://github.com/enterprise)
  + AVAILABLE ADD-ONS
    - [GitHub Advanced SecurityEnterprise-grade security features](https://github.com/security/advanced-security)
    - [Copilot for BusinessEnterprise-grade AI features](https://github.com/features/copilot/copilot-business)
    - [Premium SupportEnterprise-grade 24/7 support](https://github.com/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

[ ]
Include my email address so I can be contacted

Cancel
 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Cancel
 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm-omni)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=vllm-project%2Fvllm-omni)

Appearance settings

Resetting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[vllm-project](/vllm-project)
/
**[vllm-omni](/vllm-project/vllm-omni)**
Public

* [Notifications](/login?return_to=%2Fvllm-project%2Fvllm-omni) You must be signed in to change notification settings
* [Fork
  188](/login?return_to=%2Fvllm-project%2Fvllm-omni)
* [Star
   1.4k](/login?return_to=%2Fvllm-project%2Fvllm-omni)

A framework for efficient model inference with omni-modality models

[docs.vllm.ai/projects/vllm-omni](https://docs.vllm.ai/projects/vllm-omni "https://docs.vllm.ai/projects/vllm-omni")

### License

[Apache-2.0 license](/vllm-project/vllm-omni/blob/main/LICENSE)

[1.4k
stars](/vllm-project/vllm-omni/stargazers) [188
forks](/vllm-project/vllm-omni/forks) [Branches](/vllm-project/vllm-omni/branches) [Tags](/vllm-project/vllm-omni/tags) [Activity](/vllm-project/vllm-omni/activity)

[Star](/login?return_to=%2Fvllm-project%2Fvllm-omni)

[Notifications](/login?return_to=%2Fvllm-project%2Fvllm-omni) You must be signed in to change notification settings

* [Code](/vllm-project/vllm-omni)
* [Issues
  95](/vllm-project/vllm-omni/issues)
* [Pull requests
  42](/vllm-project/vllm-omni/pulls)
* [Actions](/vllm-project/vllm-omni/actions)
* [Projects
  0](/vllm-project/vllm-omni/projects)
* [Security

  ### Uh oh!

  There was an error while loading. Please reload this page.](/vllm-project/vllm-omni/security)
* [Insights](/vllm-project/vllm-omni/pulse)

Additional navigation options

* [Code](/vllm-project/vllm-omni)
* [Issues](/vllm-project/vllm-omni/issues)
* [Pull requests](/vllm-project/vllm-omni/pulls)
* [Actions](/vllm-project/vllm-omni/actions)
* [Projects](/vllm-project/vllm-omni/projects)
* [Security](/vllm-project/vllm-omni/security)
* [Insights](/vllm-project/vllm-omni/pulse)

# vllm-project/vllm-omni

main

[Branches](/vllm-project/vllm-omni/branches)[Tags](/vllm-project/vllm-omni/tags)

Go to file

Code

Open more actions menu

## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit   History[306 Commits](/vllm-project/vllm-omni/commits/main/) | | |
| [.buildkite](/vllm-project/vllm-omni/tree/main/.buildkite ".buildkite") | | [.buildkite](/vllm-project/vllm-omni/tree/main/.buildkite ".buildkite") |  |  |
| [.github](/vllm-project/vllm-omni/tree/main/.github ".github") | | [.github](/vllm-project/vllm-omni/tree/main/.github ".github") |  |  |
| [benchmarks](/vllm-project/vllm-omni/tree/main/benchmarks "benchmarks") | | [benchmarks](/vllm-project/vllm-omni/tree/main/benchmarks "benchmarks") |  |  |
| [docker](/vllm-project/vllm-omni/tree/main/docker "docker") | | [docker](/vllm-project/vllm-omni/tree/main/docker "docker") |  |  |
| [docs](/vllm-project/vllm-omni/tree/main/docs "docs") | | [docs](/vllm-project/vllm-omni/tree/main/docs "docs") |  |  |
| [examples](/vllm-project/vllm-omni/tree/main/examples "examples") | | [examples](/vllm-project/vllm-omni/tree/main/examples "examples") |  |  |
| [scripts](/vllm-project/vllm-omni/tree/main/scripts "scripts") | | [scripts](/vllm-project/vllm-omni/tree/main/scripts "scripts") |  |  |
| [tests](/vllm-project/vllm-omni/tree/main/tests "tests") | | [tests](/vllm-project/vllm-omni/tree/main/tests "tests") |  |  |
| [tools/pre\_commit](/vllm-project/vllm-omni/tree/main/tools/pre_commit "This path skips through empty directories") | | [tools/pre\_commit](/vllm-project/vllm-omni/tree/main/tools/pre_commit "This path skips through empty directories") |  |  |
| [vllm\_omni](/vllm-project/vllm-omni/tree/main/vllm_omni "vllm_omni") | | [vllm\_omni](/vllm-project/vllm-omni/tree/main/vllm_omni "vllm_omni") |  |  |
| [.gitattributes](/vllm-project/vllm-omni/blob/main/.gitattributes ".gitattributes") | | [.gitattributes](/vllm-project/vllm-omni/blob/main/.gitattributes ".gitattributes") |  |  |
| [.gitignore](/vllm-project/vllm-omni/blob/main/.gitignore ".gitignore") | | [.gitignore](/vllm-project/vllm-omni/blob/main/.gitignore ".gitignore") |  |  |
| [.pre-commit-config.yaml](/vllm-project/vllm-omni/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml") | | [.pre-commit-config.yaml](/vllm-project/vllm-omni/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml") |  |  |
| [.readthedocs.yml](/vllm-project/vllm-omni/blob/main/.readthedocs.yml ".readthedocs.yml") | | [.readthedocs.yml](/vllm-project/vllm-omni/blob/main/.readthedocs.yml ".readthedocs.yml") |  |  |
| [CONTRIBUTING.md](/vllm-project/vllm-omni/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") | | [CONTRIBUTING.md](/vllm-project/vllm-omni/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") |  |  |
| [LICENSE](/vllm-project/vllm-omni/blob/main/LICENSE "LICENSE") | | [LICENSE](/vllm-project/vllm-omni/blob/main/LICENSE "LICENSE") |  |  |
| [README.md](/vllm-project/vllm-omni/blob/main/README.md "README.md") | | [README.md](/vllm-project/vllm-omni/blob/main/README.md "README.md") |  |  |
| [mkdocs.yml](/vllm-project/vllm-omni/blob/main/mkdocs.yml "mkdocs.yml") | | [mkdocs.yml](/vllm-project/vllm-omni/blob/main/mkdocs.yml "mkdocs.yml") |  |  |
| [pyproject.toml](/vllm-project/vllm-omni/blob/main/pyproject.toml "pyproject.toml") | | [pyproject.toml](/vllm-project/vllm-omni/blob/main/pyproject.toml "pyproject.toml") |  |  |
| [pytest.ini](/vllm-project/vllm-omni/blob/main/pytest.ini "pytest.ini") | | [pytest.ini](/vllm-project/vllm-omni/blob/main/pytest.ini "pytest.ini") |  |  |
| View all files | | |

## Repository files navigation

* README
* Contributing
* Apache-2.0 license

![vllm-omni](https://raw.githubusercontent.com/vllm-project/vllm-omni/refs/heads/main/docs/source/logos/vllm-omni-logo.png)

### Easy, fast, and cheap omni-modality model serving for everyone

| [**Documentation**](https://vllm-omni.readthedocs.io/en/latest/) | [**User Forum**](https://discuss.vllm.ai) | [**Developer Slack**](https://slack.vllm.ai) |

---

*Latest News* ðŸ”¥

* [2025/11] vLLM community officially released [vllm-project/vllm-omni](https://github.com/vllm-project/vllm-omni) in order to support omni-modality models serving.

---

## About

[vLLM](https://github.com/vllm-project/vllm) was originally designed to support large language models for text-based autoregressive generation tasks. vLLM-Omni is a framework that extends its support for omni-modality model inference and serving:

* **Omni-modality**: Text, image, video, and audio data processing
* **Non-autoregressive Architectures**: extend the AR support of vLLM to Diffusion Transformers (DiT) and other parallel generation models
* **Heterogeneous outputs**: from traditional text generation to multimodal outputs

![vllm-omni](https://raw.githubusercontent.com/vllm-project/vllm-omni/refs/heads/main/docs/source/architecture/omni-modality-model-architecture.png)

vLLM-Omni is fast with:

* State-of-the-art AR support by leveraging efficient KV cache management from vLLM
* Pipelined stage execution overlapping for high throughput performance
* Fully disaggregation based on OmniConnector and dynamic resource allocation across stages

vLLM-Omni is flexible and easy to use with:

* Heterogeneous pipeline abstraction to manage complex model workflows
* Seamless integration with popular Hugging Face models
* Tensor, pipeline, data and expert parallelism support for distributed inference
* Streaming outputs
* OpenAI-compatible API server

vLLM-Omni seamlessly supports most popular open-source models on HuggingFace, including:

* Omni-modality models (e.g. Qwen-Omni)
* Multi-modality generation models (e.g. Qwen-Image)

## Getting Started

Visit our [documentation](https://vllm-omni.readthedocs.io/en/latest/) to learn more.

* [Installation](https://vllm-omni.readthedocs.io/en/latest/getting_started/installation/)
* [Quickstart](https://vllm-omni.readthedocs.io/en/latest/getting_started/quickstart/)
* [List of Supported Models](https://vllm-omni.readthedocs.io/en/latest/models/supported_models/)

## Contributing

We welcome and value any contributions and collaborations.
Please check out [Contributing to vLLM-Omni](https://vllm-omni.readthedocs.io/en/latest/contributing/) for how to get involved.

## Join the Community

Feel free to ask questions, provide feedbacks and discuss with fellow users of vLLM-Omni in `#sig-omni` slack channel at [slack.vllm.ai](https://slack.vllm.ai) or vLLM user forum at [discuss.vllm.ai](https://discuss.vllm.ai).

## License

Apache License 2.0, as found in the [LICENSE](/vllm-project/vllm-omni/blob/main/LICENSE) file.

## About

A framework for efficient model inference with omni-modality models

[docs.vllm.ai/projects/vllm-omni](https://docs.vllm.ai/projects/vllm-omni "https://docs.vllm.ai/projects/vllm-omni")

### Topics

[inference](/topics/inference "Topic: inference")
[pytorch](/topics/pytorch "Topic: pytorch")
[transformer](/topics/transformer "Topic: transformer")
[image-generation](/topics/image-generation "Topic: image-generation")
[diffusion](/topics/diffusion "Topic: diffusion")
[model-serving](/topics/model-serving "Topic: model-serving")
[multimodal](/topics/multimodal "Topic: multimodal")
[video-generation](/topics/video-generation "Topic: video-generation")
[audio-generation](/topics/audio-generation "Topic: audio-generation")

### Resources

[Readme](#readme-ov-file)

### License

[Apache-2.0 license](#Apache-2.0-1-ov-file)

### Contributing

[Contributing](#contributing-ov-file)

### Uh oh!

There was an error while loading. Please reload this page.

[Activity](/vllm-project/vllm-omni/activity)

[Custom properties](/vllm-project/vllm-omni/custom-properties)

### Stars

[**1.4k**
stars](/vllm-project/vllm-omni/stargazers)

### Watchers

[**17**
watching](/vllm-project/vllm-omni/watchers)

### Forks

[**188**
forks](/vllm-project/vllm-omni/forks)

[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm-omni&report=vllm-project+%28user%29)

## [Releases](/vllm-project/vllm-omni/releases)

[1
tags](/vllm-project/vllm-omni/tags)

## [Packages 0](/orgs/vllm-project/packages?repo_name=vllm-omni)

No packages published

### Uh oh!

There was an error while loading. Please reload this page.

## [Contributors 37](/vllm-project/vllm-omni/graphs/contributors)

* [![@tzhouam](https://avatars.githubusercontent.com/u/78459970?s=64&v=4)](https://github.com/tzhouam)
* [![@hsliuustc0106](https://avatars.githubusercontent.com/u/222337142?s=64&v=4)](https://github.com/hsliuustc0106)
* [![@Gaohan123](https://avatars.githubusercontent.com/u/20148503?s=64&v=4)](https://github.com/Gaohan123)
* [![@SamitHuang](https://avatars.githubusercontent.com/u/8156835?s=64&v=4)](https://github.com/SamitHuang)
* [![@ZJY0516](https://avatars.githubusercontent.com/u/86695626?s=64&v=4)](https://github.com/ZJY0516)
* [![@ywang96](https://avatars.githubusercontent.com/u/136131678?s=64&v=4)](https://github.com/ywang96)
* [![@congw729](https://avatars.githubusercontent.com/u/115451386?s=64&v=4)](https://github.com/congw729)
* [![@david6666666](https://avatars.githubusercontent.com/u/40507679?s=64&v=4)](https://github.com/david6666666)
* [![@gcanlin](https://avatars.githubusercontent.com/u/105424474?s=64&v=4)](https://github.com/gcanlin)
* [![@princepride](https://avatars.githubusercontent.com/u/29850264?s=64&v=4)](https://github.com/princepride)
* [![@Isotr0py](https://avatars.githubusercontent.com/u/41363108?s=64&v=4)](https://github.com/Isotr0py)
* [![@R2-Y](https://avatars.githubusercontent.com/u/73573651?s=64&v=4)](https://github.com/R2-Y)
* [![@qibaoyuan](https://avatars.githubusercontent.com/u/1243428?s=64&v=4)](https://github.com/qibaoyuan)
* [![@tjtanaa](https://avatars.githubusercontent.com/u/29171856?s=64&v=4)](https://github.com/tjtanaa)

[+ 23 contributors](/vllm-project/vllm-omni/graphs/contributors)

## Languages

* [Python
  98.5%](/vllm-project/vllm-omni/search?l=python)
* [Shell
  1.4%](/vllm-project/vllm-omni/search?l=shell)
* [Jinja
  0.1%](/vllm-project/vllm-omni/search?l=jinja)

## Footer

Â© 2025 GitHub,Â Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Community](https://github.community/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You canâ€™t perform that action at this time.
