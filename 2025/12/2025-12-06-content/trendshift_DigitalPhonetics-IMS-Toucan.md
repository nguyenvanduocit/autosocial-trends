---
source: trendshift
title: DigitalPhonetics/IMS-Toucan
url: https://github.com/DigitalPhonetics/IMS-Toucan
date: 2025-12-06
---

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FDigitalPhonetics%2FIMS-Toucan)

Appearance settings

* Platform

  + [GitHub Copilot

    Write better code with AI](https://github.com/features/copilot)
  + [GitHub Spark
    New

    Build and deploy intelligent apps](https://github.com/features/spark)
  + [GitHub Models
    New

    Manage and compare prompts](https://github.com/features/models)
  + [GitHub Advanced Security

    Find and fix vulnerabilities](https://github.com/security/advanced-security)
  + [Actions

    Automate any workflow](https://github.com/features/actions)

  + [Codespaces

    Instant dev environments](https://github.com/features/codespaces)
  + [Issues

    Plan and track work](https://github.com/features/issues)
  + [Code Review

    Manage code changes](https://github.com/features/code-review)
  + [Discussions

    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search

    Find more, search less](https://github.com/features/code-search)

  Explore
  + [Why GitHub](https://github.com/why-github)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)

  Integrations
  + [GitHub Marketplace](https://github.com/marketplace)
  + [MCP Registry](https://github.com/mcp)

  [View all features](https://github.com/features)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  + [Nonprofits](/solutions/industry/nonprofits)

  By use case
  + [App Modernization](/solutions/use-case/app-modernization)
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles?topic=ai)
  + [DevOps](/resources/articles?topic=devops)
  + [Security](/resources/articles?topic=security)
  + [Software Development](/resources/articles?topic=software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [Events & Webinars](https://github.com/resources/events)
  + [Ebooks & Whitepapers](https://github.com/resources/whitepapers)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://github.com/partners)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors

    Fund open source developers](/sponsors)

  + [The ReadME Project

    GitHub community articles](https://github.com/readme)

  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform

    AI-powered developer platform](/enterprise)

  Available add-ons
  + [GitHub Advanced Security

    Enterprise-grade security features](https://github.com/security/advanced-security)
  + [Copilot for business

    Enterprise-grade AI features](/features/copilot/copilot-business)
  + [Premium Support

    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

[ ]
Include my email address so I can be contacted

Cancel
 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Cancel
 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FDigitalPhonetics%2FIMS-Toucan)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=DigitalPhonetics%2FIMS-Toucan)

Appearance settings

Resetting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[DigitalPhonetics](/DigitalPhonetics)
/
**[IMS-Toucan](/DigitalPhonetics/IMS-Toucan)**
Public

* ### Uh oh!

  There was an error while loading. Please reload this page.
* [Notifications](/login?return_to=%2FDigitalPhonetics%2FIMS-Toucan) You must be signed in to change notification settings
* [Fork
  234](/login?return_to=%2FDigitalPhonetics%2FIMS-Toucan)
* [Star
   1.9k](/login?return_to=%2FDigitalPhonetics%2FIMS-Toucan)

Controllable and fast Text-to-Speech for over 7000 languages!

### License

[Apache-2.0 license](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/LICENSE)

[1.9k
stars](/DigitalPhonetics/IMS-Toucan/stargazers) [234
forks](/DigitalPhonetics/IMS-Toucan/forks) [Branches](/DigitalPhonetics/IMS-Toucan/branches) [Tags](/DigitalPhonetics/IMS-Toucan/tags) [Activity](/DigitalPhonetics/IMS-Toucan/activity)

[Star](/login?return_to=%2FDigitalPhonetics%2FIMS-Toucan)

[Notifications](/login?return_to=%2FDigitalPhonetics%2FIMS-Toucan) You must be signed in to change notification settings

* [Code](/DigitalPhonetics/IMS-Toucan)
* [Issues
  5](/DigitalPhonetics/IMS-Toucan/issues)
* [Pull requests
  0](/DigitalPhonetics/IMS-Toucan/pulls)
* [Actions](/DigitalPhonetics/IMS-Toucan/actions)
* [Security

  ### Uh oh!

  There was an error while loading. Please reload this page.](/DigitalPhonetics/IMS-Toucan/security)
* [Insights](/DigitalPhonetics/IMS-Toucan/pulse)

Additional navigation options

* [Code](/DigitalPhonetics/IMS-Toucan)
* [Issues](/DigitalPhonetics/IMS-Toucan/issues)
* [Pull requests](/DigitalPhonetics/IMS-Toucan/pulls)
* [Actions](/DigitalPhonetics/IMS-Toucan/actions)
* [Security](/DigitalPhonetics/IMS-Toucan/security)
* [Insights](/DigitalPhonetics/IMS-Toucan/pulse)

# DigitalPhonetics/IMS-Toucan

MassiveScaleToucan

[Branches](/DigitalPhonetics/IMS-Toucan/branches)[Tags](/DigitalPhonetics/IMS-Toucan/tags)

Go to file

Code

Open more actions menu

## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit   History[3,169 Commits](/DigitalPhonetics/IMS-Toucan/commits/MassiveScaleToucan/) | | |
| [.github](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/.github ".github") | | [.github](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/.github ".github") |  |  |
| [InferenceInterfaces](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/InferenceInterfaces "InferenceInterfaces") | | [InferenceInterfaces](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/InferenceInterfaces "InferenceInterfaces") |  |  |
| [Modules](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Modules "Modules") | | [Modules](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Modules "Modules") |  |  |
| [Preprocessing](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Preprocessing "Preprocessing") | | [Preprocessing](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Preprocessing "Preprocessing") |  |  |
| [Recipes](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Recipes "Recipes") | | [Recipes](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Recipes "Recipes") |  |  |
| [Utility](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Utility "Utility") | | [Utility](/DigitalPhonetics/IMS-Toucan/tree/MassiveScaleToucan/Utility "Utility") |  |  |
| [.gitignore](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/.gitignore ".gitignore") | | [.gitignore](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/.gitignore ".gitignore") |  |  |
| [LICENSE](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/LICENSE "LICENSE") | | [LICENSE](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/LICENSE "LICENSE") |  |  |
| [README.md](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/README.md "README.md") | | [README.md](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/README.md "README.md") |  |  |
| [requirements.txt](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/requirements.txt "requirements.txt") | | [requirements.txt](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/requirements.txt "requirements.txt") |  |  |
| [run\_advanced\_GUI\_demo.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_advanced_GUI_demo.py "run_advanced_GUI_demo.py") | | [run\_advanced\_GUI\_demo.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_advanced_GUI_demo.py "run_advanced_GUI_demo.py") |  |  |
| [run\_prosody\_override.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_prosody_override.py "run_prosody_override.py") | | [run\_prosody\_override.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_prosody_override.py "run_prosody_override.py") |  |  |
| [run\_scorer.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_scorer.py "run_scorer.py") | | [run\_scorer.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_scorer.py "run_scorer.py") |  |  |
| [run\_simple\_GUI\_demo.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_simple_GUI_demo.py "run_simple_GUI_demo.py") | | [run\_simple\_GUI\_demo.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_simple_GUI_demo.py "run_simple_GUI_demo.py") |  |  |
| [run\_text\_to\_file\_reader.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_text_to_file_reader.py "run_text_to_file_reader.py") | | [run\_text\_to\_file\_reader.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_text_to_file_reader.py "run_text_to_file_reader.py") |  |  |
| [run\_training\_pipeline.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_training_pipeline.py "run_training_pipeline.py") | | [run\_training\_pipeline.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_training_pipeline.py "run_training_pipeline.py") |  |  |
| [run\_zero\_shot\_lang\_emb\_injection.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_zero_shot_lang_emb_injection.py "run_zero_shot_lang_emb_injection.py") | | [run\_zero\_shot\_lang\_emb\_injection.py](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/run_zero_shot_lang_emb_injection.py "run_zero_shot_lang_emb_injection.py") |  |  |
| View all files | | |

## Repository files navigation

* README
* Apache-2.0 license

[![GitHub Repo stars](https://camo.githubusercontent.com/9678090e8388da0b91612f38cb5cd7c9bb0b015bb273344a2ec8f9798402f04d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469676974616c50686f6e65746963732f494d532d546f7563616e)](https://camo.githubusercontent.com/9678090e8388da0b91612f38cb5cd7c9bb0b015bb273344a2ec8f9798402f04d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469676974616c50686f6e65746963732f494d532d546f7563616e)
[![GitHub Repo Downloads](https://camo.githubusercontent.com/3dc809d5a4967b33de5d5913ff2c0f8cc035c4b249f41e87beb5bebe6f65e75f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f4469676974616c50686f6e65746963732f494d532d546f7563616e2f746f74616c)](https://camo.githubusercontent.com/3dc809d5a4967b33de5d5913ff2c0f8cc035c4b249f41e87beb5bebe6f65e75f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f4469676974616c50686f6e65746963732f494d532d546f7563616e2f746f74616c)
[![GitHub Release](https://camo.githubusercontent.com/61b6a69975ca79924596d4c8aa8c6ffc9660e66a5c7d82c88be0db1cea894aaf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f4469676974616c50686f6e65746963732f494d532d546f7563616e)](https://camo.githubusercontent.com/61b6a69975ca79924596d4c8aa8c6ffc9660e66a5c7d82c88be0db1cea894aaf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f4469676974616c50686f6e65746963732f494d532d546f7563616e)
[![Demo Link](https://camo.githubusercontent.com/437b09eef3499b43bc6d89b57c4bb944ca6b8a17668cfec8f71ea5b901e129eb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f44454d4f2d3c434f4c4f523e2e737667)](https://huggingface.co/spaces/Flux9665/MassivelyMultilingualTTS)

---

# Text-to-Speech for over 7000 Languages

IMS Toucan is a toolkit for training, using, and teaching state-of-the-art Text-to-Speech Synthesis, developed at the
**Institute for Natural Language Processing (IMS), University of Stuttgart, Germany**, official home of the massively
multilingual ToucanTTS system. Our system is fast, controllable, and doesn't require a ton of compute.

[![image](/DigitalPhonetics/IMS-Toucan/raw/MassiveScaleToucan/Utility/toucan.png)](/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/Utility/toucan.png)

If you find this repo useful, consider giving it a star. ‚≠ê Large numbers make me happy, and they are very motivating. If
you want to motivate me even more, you can even
consider [sponsoring this toolkit](https://github.com/sponsors/Flux9665). We only use GitHub Sponsors for this, there
are scammers on other platforms that pretend to be the creator. Don't let them fool you. The code and the models are
absolutely free, and thanks to the generous support of Hugging Faceü§ó, we even have
an [instance of the model running on GPU](https://huggingface.co/spaces/Flux9665/MassivelyMultilingualTTS) free for
anyone to use.

---

## Links ü¶ö

### Interactive Demo

[Check out our interactive massively-multi-lingual demo on Hugging Faceü§ó](https://huggingface.co/spaces/Flux9665/MassivelyMultilingualTTS)

### Dataset

[We have also published a massively multilingual TTS dataset on Hugging Faceü§ó](https://huggingface.co/datasets/Flux9665/BibleMMS)

### Languages

[A list of supported languages can be found here](https://github.com/DigitalPhonetics/IMS-Toucan/blob/MassiveScaleToucan/Utility/language_list.md)

---

## Installation ü¶â

#### Basic Requirements

Python 3.10 is the recommended version.

To install this toolkit, clone it onto the machine you want to use it on
(should have at least one cuda enabled GPU if you intend to train models on that machine. For inference, you don't need
a GPU).

If you're using Linux, you should have the following packages installed, or install them with apt-get if you haven't (on
most distributions they come pre-installed):

```
libsndfile1
espeak-ng
ffmpeg
libasound-dev
libportaudio2
libsqlite3-dev
```

Navigate to the directory you have cloned. We recommend creating and activating a
[virtual environment](https://docs.python.org/3/library/venv.html)
to install the basic requirements into. The commands below summarize everything you need to do under Linux. If you are
running Windows, the second line needs to be changed, please have a look at
the [venv documentation](https://docs.python.org/3/library/venv.html).

```
python -m venv <path_to_where_you_want_your_env_to_be>

source <path_to_where_you_want_your_env_to_be>/bin/activate

pip install --no-cache-dir -r requirements.txt
```

Run the second line everytime you start using the tool again to activate the virtual environment again, if you e.g.
logged out in the meantime. To make use of a GPU, you don't need to do anything else on a Linux machine. On a Windows
machine, have a look at [the official PyTorch website](https://pytorch.org/) for the install-command that enables GPU
support.

#### Storage configuration

If you don't want the pretrained and trained models as well as the cache files resulting from preprocessing your
datasets to be stored in the default subfolders, you can set corresponding directories globally by
editing `Utility/storage_config.py` to suit your needs (the path can be relative to the repository root directory or
absolute).

#### Pretrained Models

You don't need to use pretrained models, but it can speed things up tremendously. They will be downloaded on the fly
automatically when they are needed, thanks to Hugging Faceü§ó and [VB](https://github.com/Vaibhavs10) in particular.

#### [optional] eSpeak-NG

eSpeak-NG is an optional requirement, that handles lots of special cases in many languages, so it's good to have.

On most **Linux** environments it will be installed already, and if it is not, and you have the sufficient rights, you
can install it by simply running

```
apt-get install espeak-ng
```

For **Windows**, they provide a convenient .msi installer file
[on their GitHub release page](https://github.com/espeak-ng/espeak-ng/releases). After installation on non-linux
systems, you'll also need to tell the phonemizer library where to find your espeak installation by setting the
`PHONEMIZER_ESPEAK_LIBRARY` environment variable, which is discussed in
[this issue](https://github.com/bootphon/phonemizer/issues/44#issuecomment-1008449718).

For **Mac** it's unfortunately a lot more complicated. Thanks to Sang Hyun Park, here is a guide for installing it on
Mac:
For M1 Macs, the most convenient method to install espeak-ng onto your system is via a
[MacPorts port of espeak-ng](https://ports.macports.org/port/espeak-ng/). MacPorts itself can be installed from the
[MacPorts website](https://www.macports.org/install.php), which also requires Apple's
[XCode](https://developer.apple.com/xcode/). Once XCode and MacPorts have been installed, you can install the port of
espeak-ng via

```
sudo port install espeak-ng
```

As stated in the Windows install instructions, the espeak-ng installation will need to be set as a variable for the
phonemizer library. The environment variable is `PHONEMIZER_ESPEAK_LIBRARY` as given in the
[GitHub thread](https://github.com/bootphon/phonemizer/issues/44#issuecomment-1008449718) linked above.
However, the espeak-ng installation file you need to set this variable to is a .dylib file rather than a .dll file on
Mac. In order to locate the espeak-ng library file, you can run `port contents espeak-ng`. The specific file you are
looking for is named `libespeak-ng.dylib`.

---

## Inference ü¶¢

You can load your trained models, or the pretrained provided one, using the `InferenceInterfaces/ToucanTTSInterface.py`.
Simply create an object from it with the proper directory handle
identifying the model you want to use. The rest should work out in the background. You might want to set a language
embedding or a speaker embedding using the *set\_language* and *set\_speaker\_embedding* functions. Most things should be
self-explanatory.

An *InferenceInterface* contains two methods to create audio from text. They are
*read\_to\_file* and
*read\_aloud*.

* *read\_to\_file* takes as input a list of strings and a filename. It will synthesize the sentences in the list and
  concatenate them with a short pause inbetween and write them to the filepath you supply as the other argument.
* *read\_aloud* takes just a string, which it will then convert to speech and immediately play using the system's
  speakers. If you set the optional argument
  *view* to
  *True*, a visualization will pop up, that you need to close for the program to continue.

Their use is demonstrated in
*run\_interactive\_demo.py* and
*run\_text\_to\_file\_reader.py*.

There are simple scaling parameters to control the duration, the variance of the pitch curve and the variance of the
energy curve. You can either change them in the code when using the interactive demo or the reader, or you can simply
pass them to the interface when you use it in your own code.

To change the language of the model and see which languages are available in our pretrained model,
[have a look at the list linked here](https://github.com/DigitalPhonetics/IMS-Toucan/blob/feb573ca630823974e6ced22591ab41cdfb93674/Utility/language_list.md)

---

## Creating a new Recipe (Training Pipeline) üê£

In the directory called
*Utility* there is a file called
`path_to_transcript_dicts.py`. In this file you should write a function that returns a dictionary that has all the
absolute paths to each of the audio files in your dataset as strings as the keys and the textual transcriptions of the
corresponding audios as the values.

Then go to the directory
*TrainingInterfaces/Recipes*. In there, make a copy of the `finetuning_example_simple.py` file if you just want to
finetune on a single dataset or `finetuning_example_multilingual.py` if you want to finetune on multiple datasets,
potentially even multiple languages. We will use this copy
as reference and only make the necessary changes to use the new dataset. Find the call(s) to the *prepare\_tts\_corpus*
function. Replace the path\_to\_transcript\_dict used there with the one(s) you just created. Then change the name of the
corresponding cache directory to something that makes sense for the dataset.
Also look out for the variable *save\_dir*, which is where the checkpoints will be saved to. This is a default value, you
can overwrite it when calling
the pipeline later using a command line argument, in case you want to fine-tune from a checkpoint and thus save into a
different directory. Finally, change the
*lang* argument in the creation of the dataset and in the call to the train loop function to the ISO 639-3 language ID
that
matches your data.

The arguments that are given to the train loop in the finetuning examples are meant for the case of finetuning from a
pretrained model. If you want
to train from scratch, have a look at a different pipeline that has ToucanTTS in its name and look at the arguments
used there.

Once this is complete, we are almost done, now we just need to make it available to the
`run_training_pipeline.py` file in the top level. In said file, import the
*run* function from the pipeline you just created and give it a meaningful name. Now in the
*pipeline\_dict*, add your imported function as value and use as key a shorthand that makes sense.

---

## Training a Model ü¶ú

Once you have a recipe built, training is super easy:

```
python run_training_pipeline.py <shorthand of the pipeline>
```

You can supply any of the following arguments, but don't have to (although for training you should definitely specify at
least a GPU ID).

```
--gpu_id <ID of the GPU you wish to use, as displayed with nvidia-smi, default is cpu. If multiple GPUs are provided (comma separated), then distributed training will be used, but the script has to be started with torchrun.>

--resume_checkpoint <path to a checkpoint to load>

--resume (if this is present, the furthest checkpoint available will be loaded automatically)

--finetune (if this is present, the provided checkpoint will be fine-tuned on the data from this pipeline)

--model_save_dir <path to a directory where the checkpoints should be saved>

--wandb (if this is present, the logs will be synchronized to your weights&biases account, if you are logged in on the command line)

--wandb_resume_id <the id of the run you want to resume, if you are using weights&biases (you can find the id in the URL of the run)>
```

For multi-GPU training, you have to supply multiple GPU ids (comma separated) and start the script with torchrun. You
also have to specify the number of GPUs. This has to match the number of IDs that you supply. Careful: torchrun is
incompatible with nohup! Use tmux instead to keep the script running after you log out of the shell.

```
torchrun --standalone --nproc_per_node=4 --nnodes=1 run_training_pipeline.py <shorthand of the pipeline> --gpu_id "0,1,2,3"
```

After every epoch (or alternatively after certain step counts), some logs will be written to the console and to the
Weights and Biases website, if you are logged in and set the flag. If you get cuda out of memory errors, you need to
decrease
the batchsize in the arguments of the call to the training\_loop in the pipeline you are running. Try decreasing the
batchsize in small steps until you get no more out of cuda memory errors.

In the directory you specified for saving, checkpoint files and spectrogram visualization
data will appear. Since the checkpoints are quite big, only the five most recent ones will be kept. The amount of
training steps highly depends on the data you are using and whether you're finetuning from a pretrained checkpoint or
training from scratch. The fewer data you have, the fewer steps you should take to prevent a possible collapse. If
you want to stop earlier, just kill the process, since everything is daemonic all the child-processes should die with
it. In case there are some ghost-processes left behind, you can use the following command to find them and kill them
manually.

```
fuser -v /dev/nvidia*
```

Whenever a checkpoint is saved, a compressed version that can be used for inference is also created, which is named
*best.py*

---

## FAQ üêì

Here are a few points that were brought up by users:

* How can I figure out if my data has outliers or similar problems? -- There is a scorer that can find and even remove
  samples from your dataset cache that have extraordinarily high loss values, have a look at `run_scorer.py`.
* My error message shows GPU0, even though I specified a different GPU -- The way GPU selection works is that the
  specified GPU is set as the only visible device, in order to avoid backend stuff running accidentally on different
  GPUs. So internally the program will name the device GPU0, because it is the only GPU it can see. It is actually
  running on the GPU you specified.
* read\_to\_file produces strange outputs -- Check if you're passing a list to the method or a string. Since strings can
  be
  iterated over, it might not throw an error, but a list of strings is expected.
* `UserWarning: Detected call of lr_scheduler.step() before optimizer.step().` -- We use a custom scheduler, and torch
  incorrectly thinks that we call the scheduler and the optimizer in the wrong order. Just ignore this warning, it is
  completely meaningless.
* `WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. [...]` -- Another meaningless warning. We actually don't
  use xFormers ourselves, it is just part of the dependencies of one of our dependencies, but it is not used at any
  place.
* `The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows. [...]` -- Just
  happens under Windows and doesn't affect anything.
* `WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1) [...]` -- We have no idea why espeak started
  giving out this warning, however it doesn't seem to affect anything, so it seems safe to ignore.
* Loss turns to `NaN` -- The default learning rates work on clean data. If your data is less clean, try using the scorer
  to find problematic samples, or reduce the learning rate. The most common problem is there being pauses in the speech,
  but nothing that hints at them in the text. That's why ASR corpora, which leave out punctuation, are usually difficult
  to use for TTS.

---

## Acknowledgements ü¶Ü

The basic PyTorch modules of FastSpeech 2 and GST are taken from
[ESPnet](https://github.com/espnet/espnet), the PyTorch modules of
HiFi-GAN are taken from the [ParallelWaveGAN repository](https://github.com/kan-bayashi/ParallelWaveGAN).
Some modules related to the ConditionalFlowMatching based PostNet as outlined in MatchaTTS are taken
from the [official MatchaTTS codebase](https://github.com/shivammehta25/Matcha-TTS) and some are taken
from [the StableTTS codebase](https://github.com/KdaiP/StableTTS).
For grapheme-to-phoneme conversion, we rely on the aforementioned eSpeak-NG as
well as [transphone](https://github.com/xinjli/transphone). We
use [encodec, a neural audio codec](https://github.com/yangdongchao/AcademiCodec) as intermediate representation
for caching the train data to save space.

## Citation üêß

[![Star History Chart](https://camo.githubusercontent.com/08bdd0b49e613efc1b4076071b56936c7efb3e8db5a7d34b1bed5be01c372171/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d4469676974616c50686f6e65746963732f494d532d546f7563616e26747970653d44617465)](https://star-history.com/#DigitalPhonetics/IMS-Toucan&Date)

### Introduction of the Toolkit [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/v1.0)

```
@inproceedings{lux2021toucan,
  year         = 2021,
  title        = {{The IMS Toucan system for the Blizzard Challenge 2021}},
  author       = {Florian Lux and Julia Koch and Antje Schweitzer and Ngoc Thang Vu},
  booktitle    = {Blizzard Challenge Workshop},
  publisher    = {ISCA Speech Synthesis SIG}
}
```

### Adding Articulatory Features and Meta-Learning Pretraining [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/v1.1)

```
@inproceedings{lux2022laml,
  year         = 2022,
  title        = {{Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features}},
  author       = {Florian Lux and Ngoc Thang Vu},
  booktitle    = {ACL}
}
```

### Adding Exact Prosody-Cloning Capabilities [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/v2.2)

```
@inproceedings{lux2022cloning,
  year         = 2022,
  title        = {{Exact Prosody Cloning in Zero-Shot Multispeaker Text-to-Speech}},
  author       = {Lux, Florian and Koch, Julia and Vu, Ngoc Thang},
  booktitle    = {SLT},
  publisher    = {IEEE}
}
```

### Adding Language Embeddings and Word Boundaries [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/v2.2)

```
@inproceedings{lux2022lrms,
  year         = 2022,
  title        = {{Low-Resource Multilingual and Zero-Shot Multispeaker TTS}},
  author       = {Florian Lux and Julia Koch and Ngoc Thang Vu},
  booktitle    = {AACL}
}
```

### Adding Controllable Speaker Embedding Generation [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/v2.3)

```
@inproceedings{lux2023controllable,
  year         = 2023,
  title        = {{Low-Resource Multilingual and Zero-Shot Multispeaker TTS}},
  author       = {Florian Lux and Pascal Tilli and Sarina Meyer and Ngoc Thang Vu},
  booktitle    = {Interspeech}
  publisher    = {ISCA}
}
```

### Our Contribution to the Blizzard Challenge 2023 [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/v2.b)

```
@inproceedings{lux2023blizzard,
  year         = 2023,
  title        = {{The IMS Toucan System for the Blizzard Challenge 2023}},
  author       = {Florian Lux and Julia Koch and Sarina Meyer and Thomas Bott and Nadja Schauffler and Pavel Denisov and Antje Schweitzer and Ngoc Thang Vu},
  booktitle    = {Blizzard Challenge Workshop},
  publisher    = {ISCA Speech Synthesis SIG}
}
```

### Introducing the first TTS System in over 7000 languages [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/v3.0)

```
@inproceedings{lux2024massive,
  year         = 2024,
  title        = {{Meta Learning Text-to-Speech Synthesis in over 7000 Languages}},
  author       = {Florian Lux and Sarina Meyer and Lyonel Behringer and Frank Zalkow and Phat Do and Matt Coler and  Emanu√´l A. P. Habets and Ngoc Thang Vu},
  booktitle    = {Interspeech}
  publisher    = {ISCA}
}
```

### Introducing Text based in-context-Prompting to NAR TTS [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/releases/tag/2.p)

```
@inproceedings{bott2024prompting,
  year         = 2024,
  title        = {{Controlling Emotion in Text-to-Speech with Natural Language Prompts}},
  author       = {Thomas Bott and Florian Lux and Ngoc Thang Vu},
  booktitle    = {Interspeech}
  publisher    = {ISCA}
}
```

### Investigating Stochastic Prosody Modeling [[associated code and models]](https://github.com/DigitalPhonetics/IMS-Toucan/tree/StochasticProsodyModeling)

```
@inproceedings{mayer2025stochastic,
  year         = 2025,
  title        = {{Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis}},
  author       = {Paul Mayer and Florian Lux and Alejandro P\'erez-Gonz\'alez-de-Martos and Angelina Elizarova and Lindsey Vanderlyn and Dirk V\"ath and Ngoc Thang Vu},
  booktitle    = {Interspeech}
  publisher    = {ISCA}
}
```

## About

Controllable and fast Text-to-Speech for over 7000 languages!

### Topics

[text-to-speech](/topics/text-to-speech "Topic: text-to-speech")
[deep-learning](/topics/deep-learning "Topic: deep-learning")
[toolkit](/topics/toolkit "Topic: toolkit")
[speech](/topics/speech "Topic: speech")
[pytorch](/topics/pytorch "Topic: pytorch")
[tts](/topics/tts "Topic: tts")
[speech-synthesis](/topics/speech-synthesis "Topic: speech-synthesis")
[speech-processing](/topics/speech-processing "Topic: speech-processing")

### Resources

[Readme](#readme-ov-file)

### License

[Apache-2.0 license](#Apache-2.0-1-ov-file)

### Uh oh!

There was an error while loading. Please reload this page.

[Activity](/DigitalPhonetics/IMS-Toucan/activity)

[Custom properties](/DigitalPhonetics/IMS-Toucan/custom-properties)

### Stars

[**1.9k**
stars](/DigitalPhonetics/IMS-Toucan/stargazers)

### Watchers

[**23**
watching](/DigitalPhonetics/IMS-Toucan/watchers)

### Forks

[**234**
forks](/DigitalPhonetics/IMS-Toucan/forks)

[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FDigitalPhonetics%2FIMS-Toucan&report=DigitalPhonetics+%28user%29)

## [Releases 14](/DigitalPhonetics/IMS-Toucan/releases)

[GUI for precise control

Latest

Oct 7, 2024](/DigitalPhonetics/IMS-Toucan/releases/tag/v3.1.2)

[+ 13 releases](/DigitalPhonetics/IMS-Toucan/releases)

## Sponsor this project

 Sponsor

### Uh oh!

There was an error while loading. Please reload this page.

[Learn more about GitHub Sponsors](/sponsors)

### Uh oh!

There was an error while loading. Please reload this page.

## [Contributors 7](/DigitalPhonetics/IMS-Toucan/graphs/contributors)

* [![@Flux9665](https://avatars.githubusercontent.com/u/33219702?s=64&v=4)](https://github.com/Flux9665)
* [![@lbehringer](https://avatars.githubusercontent.com/u/36770840?s=64&v=4)](https://github.com/lbehringer)
* [![@AlexSteveChungAlvarez](https://avatars.githubusercontent.com/u/42816278?s=64&v=4)](https://github.com/AlexSteveChungAlvarez)
* [![@Adamantcat](https://avatars.githubusercontent.com/u/25061158?s=64&v=4)](https://github.com/Adamantcat)
* [![@Ca-ressemble-a-du-fake](https://avatars.githubusercontent.com/u/91517923?s=64&v=4)](https://github.com/Ca-ressemble-a-du-fake)
* [![@khof312](https://avatars.githubusercontent.com/u/6764017?s=64&v=4)](https://github.com/khof312)
* [![@Vaibhavs10](https://avatars.githubusercontent.com/u/18682411?s=64&v=4)](https://github.com/Vaibhavs10)

## Languages

* [Python
  100.0%](/DigitalPhonetics/IMS-Toucan/search?l=python)

## Footer

¬© 2025 GitHub,¬†Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Community](https://github.community/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can‚Äôt perform that action at this time.
